{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dataclasses import dataclass\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchtyping import TensorType as TT, patch_typeguard\n",
    "\n",
    "from hand import Transformer, Task, Perfs\n",
    "from viz.pygame_mainloop import pygame_mainloop_thread_start\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "patch_typeguard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3 (SDL 2.26.4, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Assets: /home/diego/ai/hand-transformer/viz/assets\n",
      "Images: /home/diego/ai/hand-transformer/viz/assets/images\n"
     ]
    }
   ],
   "source": [
    "crash_kernel = pygame_mainloop_thread_start(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/ai/hand-transformer/viz/pygame_mainloop.py\", line 21, in run_app\n",
      "    pyapp.run()\n",
      "  File \"/home/diego/ai/hand-transformer/viz/engine/app.py\", line 62, in run\n",
      "    self.clock.tick(self.state.FPS)\n",
      "AttributeError: 'NoneType' object has no attribute 'FPS'\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App crashed!!!\n"
     ]
    }
   ],
   "source": [
    "crash_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArithmeticTask(Task):\n",
    "\n",
    "    def __init__(self, prompt_len: int = 100,\n",
    "                    max_number: int = 1000,\n",
    "                    ops: tuple[str, ...] = (\"+\",),\n",
    "                    max_operends: int = 2,\n",
    "                    parens_prob: float = 0,\n",
    "                    allow_negative: bool = False,\n",
    "                    max_decimals: int = 0) -> None:\n",
    "        self.max_number = max_number\n",
    "        self.ops = ops\n",
    "        self.max_operends = max_operends\n",
    "        self.parens_prob = parens_prob\n",
    "        self.allow_negative = allow_negative\n",
    "        self.max_decimals = max_decimals\n",
    "\n",
    "        super().__init__(list(\"0123456789.+-*=()/%^\"), prompt_len, pad_token=\"_\")\n",
    "\n",
    "    def construct(self, n_operends) -> str:\n",
    "        if n_operends == 1:\n",
    "            if self.allow_negative:\n",
    "                mini = -self.max_number\n",
    "            else:\n",
    "                mini = 0\n",
    "            if self.max_decimals > 0:\n",
    "                rounding = random.randrange(0, self.max_decimals)\n",
    "                return str(round(random.uniform(mini, self.max_number), rounding))\n",
    "            else:\n",
    "                return str(random.randrange(mini, self.max_number))\n",
    "\n",
    "        if n_operends == self.max_operends and random.random() > 1 / self.max_operends:\n",
    "            return self.construct(random.randrange(1, self.max_operends))\n",
    "        \n",
    "        n_ops_left = random.randrange(1, n_operends)\n",
    "        a = self.construct(n_ops_left)\n",
    "        b = self.construct(n_operends - n_ops_left)\n",
    "        op = random.choice(self.ops)\n",
    "        ret = f\"{a}{op}{b}\"\n",
    "        if random.random() < self.parens_prob:\n",
    "            ret = f\"({ret})\"\n",
    "        return ret\n",
    "\n",
    "    def dataset_size(self, n_operands=None) -> int:\n",
    "        if n_operands is None:\n",
    "            n_operands = self.max_operends\n",
    "\n",
    "        if n_operands == 1:\n",
    "            if self.allow_negative:\n",
    "                range_ = self.max_number * 2\n",
    "            else:\n",
    "                range_ = self.max_number\n",
    "            return range_ * 10 ** self.max_decimals\n",
    "\n",
    "        if self.parens_prob > 0:\n",
    "            raise NotImplementedError(\"Parentheses are not supported yet\")\n",
    "\n",
    "        item_possibilities = self.dataset_size(1)\n",
    "        total = 0\n",
    "        for n_ops in range(n_operands):\n",
    "            total += item_possibilities ** (n_ops + 1) * len(self.ops) ** n_ops\n",
    "        return total\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "    def generate(self, batch_size: str, unique=True, max_tries=30) -> tuple[list[str], list[str]]:\n",
    "        prompts = []\n",
    "        answers = [] \n",
    "        tries = 0\n",
    "        while len(prompts) < batch_size:\n",
    "            c = self.construct(self.max_operends)\n",
    "            try:\n",
    "                res = str(eval(c))\n",
    "            except:\n",
    "                res = 'nan'\n",
    "\n",
    "            cut = random.randrange(0, len(res))\n",
    "            prompt = f\"{c}={res[:cut]}\"\n",
    "            answer = res[cut]\n",
    "\n",
    "            if len(prompt) > self.prompt_len:\n",
    "                continue\n",
    "            if unique and prompt in prompts:\n",
    "                tries += 1\n",
    "                if tries > max_tries:\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            prompts.append(prompt)\n",
    "            answers.append(answer)\n",
    "            tries = 0\n",
    "\n",
    "        return prompts, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3192"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = ArithmeticTask(\n",
    "    prompt_len=20,\n",
    "    max_number=56,\n",
    "    ops=(\"+\",),\n",
    "    max_operends=2,\n",
    "    parens_prob=0,\n",
    "    allow_negative=False,\n",
    "    max_decimals=0,\n",
    ")\n",
    "task.dataset_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    voc_size=len(task.tokens),\n",
    "    embedding_size=64,\n",
    "    depth=4,\n",
    "    heads=4,\n",
    "    max_prompt_len=task.prompt_len,\n",
    "    mlp_dims=(64 * 4,),\n",
    ")\n",
    "model.init_weights()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=5e-5, weight_decay=5e-6, momentum=0.95)\n",
    "perfs = Perfs([100])\n",
    "saves = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Save:\n",
    "    model: dict\n",
    "    timestamp: float\n",
    "    note: str\n",
    "\n",
    "saves: list[Save] = []\n",
    "saves = torch.load(\"saves.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(note: str = \"no comment\"):\n",
    "    saves.append(Save(\n",
    "        deepcopy(model.state_dict()),\n",
    "        time.time(),\n",
    "        note,\n",
    "    ))\n",
    "    torch.save(saves, \"saves.pt\")\n",
    "    print(f\"Saved model state to {len(saves) - 1}, note: {note} at {time.ctime()}\")\n",
    "def recall(n=-1):\n",
    "    model.load_state_dict(deepcopy(saves[n].model))\n",
    "    n = len(saves) + n if n < 0 else n\n",
    "    print(f\"Recalled model state from {n} note: {saves[n].note} ({len(saves) - 1} total saves)\")\n",
    "def set_hyperparams(optim, lr=None, weight_decay=None, momentum=None):\n",
    "    for g in optim.param_groups:\n",
    "        if lr is not None:\n",
    "            g['lr'] = lr\n",
    "        if weight_decay is not None:\n",
    "            g['weight_decay'] = weight_decay\n",
    "        if momentum is not None:\n",
    "            g['momentum'] = momentum\n",
    "def call_once(f):\n",
    "    called = False\n",
    "    def wrapper(*args, **kwargs):\n",
    "        nonlocal called\n",
    "        if not called:\n",
    "            called = True\n",
    "            return f(*args, **kwargs)\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalled model state from 40 note: Learned to add up to 56 (40 total saves)\n"
     ]
    }
   ],
   "source": [
    "recall(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model state to 72, note: Learned to add up to 649 at Fri Mar 17 10:54:34 2023\n"
     ]
    }
   ],
   "source": [
    "lr = 5e-5\n",
    "weight_decay = 1e-6\n",
    "def curriculum():\n",
    "    global lr\n",
    "    def loss(last=10):\n",
    "        if len(perfs.loss) < last:\n",
    "            return 100\n",
    "        return sum(perfs.loss[-last:]) / last\n",
    "\n",
    "    def variance(last=10):\n",
    "        if len(perfs.loss) < last:\n",
    "            return 100\n",
    "        return torch.var(torch.tensor(perfs.loss[-last:]))\n",
    "\n",
    "    # model.init_weights()\n",
    "    steps = 0\n",
    "    while True:\n",
    "        steps += 1\n",
    "        yield\n",
    "\n",
    "        if steps > 10 and loss() < 0.001:\n",
    "            steps = 0\n",
    "            lr = 5e-5\n",
    "            set_hyperparams(optim, lr, weight_decay)\n",
    "            save(f\"Learned to add up to {task.max_number-1}\")\n",
    "            if task.max_number < 650:\n",
    "                task.max_number += 1 + task.max_number // 15\n",
    "            else:\n",
    "                task.allow_negative = True\n",
    "\n",
    "        # if steps > 20 and variance(20) > loss(20):\n",
    "        #     steps = 0\n",
    "        #     lr *= 0.7\n",
    "        #     lr = max(lr, 1e-5)\n",
    "        #     set_hyperparams(optim, lr, weight_decay)\n",
    "\n",
    "        # if loss doesn't go down much, increase learning rate\n",
    "        if steps > 50 and lr < 70e-5 and abs(loss(50) - loss(10)) < 0.1:\n",
    "            steps = 0\n",
    "            lr *= 1.3\n",
    "            lr = min(lr, 70e-5)\n",
    "            set_hyperparams(optim, lr, weight_decay)\n",
    "curr = curriculum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@call_once\n",
    "def modify():\n",
    "    global lr, weight_decay\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-5\n",
    "    set_hyperparams(optim, lr=lr, momentum=0.98, weight_decay=weight_decay)\n",
    "    # with torch.no_grad():\n",
    "    #     emb = model.embedding.weight\n",
    "        # emb[-1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "def logic():\n",
    "    return\n",
    "    next(curr)\n",
    "    modify()\n",
    "\n",
    "    x, y = task.generate_batch(batch_size)\n",
    "    optim.zero_grad()\n",
    "    loss = model.loss(x, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    perfs.update(loss, model, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model state to 41, note: Learned to add up to 55 at Fri Mar 17 04:55:22 2023\n",
      "Saved model state to 42, note: Learned to add up to 59 at Fri Mar 17 04:57:50 2023\n",
      "Saved model state to 43, note: Learned to add up to 64 at Fri Mar 17 05:01:22 2023\n",
      "Saved model state to 44, note: Learned to add up to 69 at Fri Mar 17 05:04:19 2023\n",
      "Saved model state to 45, note: Learned to add up to 74 at Fri Mar 17 05:07:28 2023\n",
      "Saved model state to 46, note: Learned to add up to 80 at Fri Mar 17 05:10:09 2023\n",
      "Saved model state to 47, note: Learned to add up to 86 at Fri Mar 17 05:13:22 2023\n",
      "Saved model state to 48, note: Learned to add up to 92 at Fri Mar 17 05:16:38 2023\n",
      "Saved model state to 49, note: Learned to add up to 99 at Fri Mar 17 05:20:05 2023\n",
      "Saved model state to 50, note: Learned to add up to 106 at Fri Mar 17 05:28:49 2023\n",
      "Saved model state to 51, note: Learned to add up to 114 at Fri Mar 17 05:39:05 2023\n",
      "Saved model state to 52, note: Learned to add up to 122 at Fri Mar 17 05:51:16 2023\n",
      "Saved model state to 53, note: Learned to add up to 131 at Fri Mar 17 06:02:15 2023\n",
      "Saved model state to 54, note: Learned to add up to 140 at Fri Mar 17 06:11:32 2023\n",
      "Saved model state to 55, note: Learned to add up to 150 at Fri Mar 17 06:18:41 2023\n",
      "Saved model state to 56, note: Learned to add up to 161 at Fri Mar 17 06:32:54 2023\n",
      "Saved model state to 57, note: Learned to add up to 172 at Fri Mar 17 06:43:34 2023\n",
      "Saved model state to 58, note: Learned to add up to 184 at Fri Mar 17 06:58:19 2023\n",
      "Saved model state to 59, note: Learned to add up to 197 at Fri Mar 17 07:09:23 2023\n",
      "Saved model state to 60, note: Learned to add up to 211 at Fri Mar 17 07:27:09 2023\n",
      "Saved model state to 61, note: Learned to add up to 226 at Fri Mar 17 07:45:50 2023\n",
      "Saved model state to 62, note: Learned to add up to 242 at Fri Mar 17 07:59:49 2023\n",
      "Saved model state to 63, note: Learned to add up to 259 at Fri Mar 17 08:09:08 2023\n",
      "Saved model state to 64, note: Learned to add up to 277 at Fri Mar 17 08:19:56 2023\n",
      "Saved model state to 65, note: Learned to add up to 296 at Fri Mar 17 08:33:56 2023\n",
      "Saved model state to 66, note: Learned to add up to 316 at Fri Mar 17 08:50:59 2023\n",
      "Saved model state to 67, note: Learned to add up to 338 at Fri Mar 17 09:03:56 2023\n",
      "Saved model state to 68, note: Learned to add up to 361 at Fri Mar 17 09:20:18 2023\n",
      "Saved model state to 69, note: Learned to add up to 386 at Fri Mar 17 09:30:55 2023\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     logic()\n",
      "Cell \u001b[0;32mIn [11], line 10\u001b[0m, in \u001b[0;36mlogic\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m x, y \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mgenerate_batch(batch_size)\n\u001b[1;32m      9\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mloss(x, y)\n\u001b[1;32m     11\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     12\u001b[0m optim\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/ai/hand-transformer/hand.py:276\u001b[0m, in \u001b[0;36mTransformer.loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, x: TensorType[\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    275\u001b[0m          y: TensorType[\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m TensorType[\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m--> 276\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcross_entropy(logits, y)\n",
      "File \u001b[0;32m~/ai/hand-transformer/hand.py:265\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    263\u001b[0m with_pos \u001b[39m=\u001b[39m embeded \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_encoder\n\u001b[1;32m    264\u001b[0m debug(with_pos, \u001b[39m\"\u001b[39m\u001b[39membed+pos\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 265\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(with_pos)\n\u001b[1;32m    266\u001b[0m out \u001b[39m=\u001b[39m x[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)  \u001b[39m# only the last token is the prediction\u001b[39;00m\n\u001b[1;32m    267\u001b[0m unembeded \u001b[39m=\u001b[39m out \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munembedding\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ai/hand-transformer/hand.py:229\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    227\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(x)\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(x)\n\u001b[1;32m    230\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ai/hand-transformer/hand.py:190\u001b[0m, in \u001b[0;36mResidualMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    188\u001b[0m initial \u001b[39m=\u001b[39m x\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m l, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[0;32m--> 190\u001b[0m     x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m    191\u001b[0m     debug(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer, \u001b[39m\"\u001b[39m\u001b[39mmlp\u001b[39m\u001b[39m\"\u001b[39m, l)\n\u001b[1;32m    192\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    logic()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pygame vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz.utils import *\n",
    "from viz.engine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = answers = None\n",
    "avg_acc = 0\n",
    "\n",
    "def new_prompts_to_show():\n",
    "    global prompts, answers, avg_acc\n",
    "    prompts, answers = task.generate(10000, False, 100)\n",
    "\n",
    "    # pick only the few worst and few best\n",
    "    pred: TT = model(task.encode(prompts, task.prompt_len))\n",
    "    \n",
    "    answers_pos = task.encode(answers)\n",
    "    correct_proba = torch.gather(pred.softmax(1), 1, answers_pos).squeeze()\n",
    "    avg_acc = correct_proba.mean().item()\n",
    "\n",
    "    losses = torch.nn.functional.cross_entropy(pred, task.encode(answers).squeeze(), reduction=\"none\")\n",
    "    losses, idx = losses.sort()\n",
    "\n",
    "    idx = torch.cat([idx[:-20:len(idx)//10], idx[-20::2]])\n",
    "    prompts = [prompts[i] for i in idx]\n",
    "    answers = [answers[i] for i in idx]\n",
    "new_prompts_to_show()\n",
    "\n",
    "def draw(gfx: GFX):\n",
    "    return\n",
    "    with torch.no_grad():\n",
    "        # if random.random() < 1 / (30 * 2):\n",
    "        #     new_prompts_to_show()\n",
    "        losses = torch.tensor(perfs.loss[-500:])\n",
    "        r = gfx.plot(losses, \"orange\", \"Loss\", axis=1, topleft=(100, 100))\n",
    "        gfx.plot(losses.clamp_max(0.1), \"orange\", \"Loss\", axis=1, topleft=r.topright)\n",
    "        r.inflate_ip(0, 20)\n",
    "        pred: TT['batch', 'token'] = model(task.encode(prompts, task.prompt_len))\n",
    "        for p, a, g in zip(prompts, answers, pred):\n",
    "            if p == prompts[-10]:\n",
    "                r.y += 20\n",
    "            g = g.softmax(0)\n",
    "            p = task.pad_token * (task.prompt_len - len(p)) + p\n",
    "            r = gfx.text(f\"{p} â†’ {a}\", topleft=r.bottomleft)\n",
    "            r2 = r.inflate(40, 0)\n",
    "            for prob, t in zip(g, task.tokens):\n",
    "                color = mix((0, 0, 0), (255, 0, 0), prob.item())\n",
    "                r2 = gfx.text(f\"{t}\", color=color, topleft=r2.topright)\n",
    "            # add prob of correct answer as %\n",
    "            r2 = gfx.text(f\"  {g[task.tokens.index(a)].item():.0%}\", topleft=r2.topright)\n",
    "\n",
    "        # using torch.gather\n",
    "        answer_positions = task.encode(answers)\n",
    "        correct_proba = torch.gather(pred.softmax(1), 1, answer_positions).squeeze()\n",
    "        # accuracy = correct_proba.mean().item()\n",
    "\n",
    "        worse_accuracy = correct_proba.min().item()\n",
    "\n",
    "    r = gfx.texts(\n",
    "        f\"epoch: {len(perfs.loss)}\",\n",
    "        f\"max_number: {task.max_number-1}\",\n",
    "        f\"avg accuracy: {avg_acc:.1%}\",\n",
    "        f\"worst accuracy: {worse_accuracy:.0%}\",\n",
    "        f\"loss: {sum(losses[-10:])/10:.5f}\",\n",
    "        f\"target loss: {2 / task.dataset_size():.5f}\",\n",
    "        f\"lr: {lr:.5f}\",\n",
    "        f\"weight_decay: {weight_decay}\",\n",
    "        topleft=r.bottomleft + Vec2(0, 10))\n",
    "    # transformer_outline(gfx, model, r.bottomleft)\n",
    "    model.blocks[0]: TransformerBlock\n",
    "    # draw_matrix(gfx, model.blocks[2].attention.heads[3].qk(), 20, \"Embedding\", topleft=r.bottomleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 423150\n",
      "295:45 Learned to add up to 242\n",
      "305:3 Learned to add up to 259\n",
      "315:52 Learned to add up to 277\n",
      "329:52 Learned to add up to 296\n",
      "346:55 Learned to add up to 316\n",
      "359:52 Learned to add up to 338\n",
      "376:14 Learned to add up to 361\n",
      "386:51 Learned to add up to 386\n",
      "400:19 Learned to add up to 412\n",
      "409:49 Learned to add up to 440\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", task.dataset_size())\n",
    "for s in saves[-10:]:\n",
    "    delta = s.timestamp - saves[0].timestamp\n",
    "    # human readable fmt\n",
    "    delta = f\"{delta // 60:.0f}:{delta % 60:.0f}\"\n",
    "    print(f\"{delta} {s.note}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faa5858c400>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot times of saves\n",
    "times = [s.timestamp - saves[1].timestamp for s in saves[1:]]\n",
    "maxis = [int(s.note.rpartition(\" \")[-1]) for s in saves[1:]]\n",
    "plt.plot([(s.timestamp - saves[0].timestamp) / 60 for s in saves])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model state to 73, note: 88% accuracy up to Â± 649 at Fri Mar 17 11:30:21 2023\n"
     ]
    }
   ],
   "source": [
    "save(\"88% accuracy up to Â± 649\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
